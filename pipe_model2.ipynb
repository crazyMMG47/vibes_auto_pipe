{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vibes Lab Mask Automation Pipeline Development (Draft 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second trial with input as nii files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "nifti = nib.load(\"/home/smooi/vibes_auto_pipe/data/Cc_just_bet_nifti/Cc106_t2bet.nii\")\n",
    "# retrieve nifti data\n",
    "data = nifti.get_fdata()\n",
    "data = (data - np.min(data)) / (np.max(data) - np.min(data)) * 255.0\n",
    "data = data.astype(np.uint8)  # Convert to 8-bit unsigned integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 13:37:31.147942: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64\n",
      "2025-02-14 13:37:31.147993: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-02-14 13:37:32.620335: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-02-14 13:37:32.621963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-02-14 13:37:32.776060: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-02-14 13:37:32.776121: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (MMServer): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# config to use the gpu of the server \n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.043] global loadsave.cpp:848 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n"
     ]
    }
   ],
   "source": [
    "print(data.shape) # (96, 96, 48) # there are 48 slices\n",
    "import cv2\n",
    "import os\n",
    "output_dir = \"/home/smooi/vibes_auto_pipe/output\"\n",
    "\n",
    "# Iterate through the slices \n",
    "for i in range(data.shape[2]): #iter thru 1 to 48 \n",
    "    slice_ = data[:, :, i] # 2D slices\n",
    "    resized_slice = cv2.resize(slice_, (160, 160), interpolation=cv2.INTER_AREA)\n",
    "    # rotate the image by 90 degrees counterclockwise \n",
    "    rotated_slice = cv2.rotate(resized_slice, cv2.ROTATE_90_COUNTERCLOCKWISE)  \n",
    "    # Scale to Full Grayscale Range [0, 255]\n",
    "    img_max_range = rotated_slice.max()\n",
    "    output_img = (rotated_slice / img_max_range) * 255\n",
    "    output_path = os.path.join(output_dir, f\"{i:03d}.png\") \n",
    "    cv2.imwrite(output_path, output_img)\n",
    "    \n",
    "# retrieve the original shape of the image here \n",
    "# so that we can reshape it back to the original shape at the end in Python code\n",
    "w = data.shape[0]\n",
    "h = data.shape[1]\n",
    "s = data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (160, 160)\n",
      "Data Type: uint8\n",
      "Min Pixel Value: 0\n",
      "Max Pixel Value: 255\n"
     ]
    }
   ],
   "source": [
    "# load a png file and explore its min and max\n",
    "picture = \"/home/smooi/vibes_auto_pipe/output/001.png\"\n",
    "\n",
    "# chatgpt's code to examine a png file\n",
    "image = cv2.imread(picture, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Image Shape: {image.shape}\")  # Dimensions: (height, width, channels)\n",
    "print(f\"Data Type: {image.dtype}\")    # Pixel data type (e.g., uint8)\n",
    "print(f\"Min Pixel Value: {image.min()}\")  # Minimum pixel intensity\n",
    "print(f\"Max Pixel Value: {image.max()}\")  # Maximum pixel intensity\n",
    "\n",
    "# Currently, there's no channel info\n",
    "# It is also observed that the pixel range is not Scale to Full Grayscale Range [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Image Batch Shape: (56, 160, 160, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 13:39:26.374220: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mydir = \"/home/smooi/vibes_auto_pipe/output\"\n",
    "\n",
    "def prepare_image_for_tf(img):\n",
    "    brain_img = tf.io.read_file(img)\n",
    "    brain_img = tf.io.decode_png(brain_img, channels=1) # brain img channels=1 greyscale\n",
    "    brain_img = tf.image.resize(brain_img, [160, 160]) # Necessary since inputs may be varying in size from different trials\n",
    "    brain_img = tf.cast(brain_img, tf.float32)  \n",
    "    \n",
    "    return brain_img\n",
    "\n",
    "# make this to be a global variable \n",
    "store_filenames = []\n",
    "def retrieve_n_sort(directory):\n",
    "    # List Comprehensions\n",
    "    filenames = [filename for filename in os.listdir(directory) if filename.endswith(\".png\")]\n",
    "    # lambda func\n",
    "    filenames.sort(key=lambda x: int(x.split('.')[0].split('/')[-1]))  # Sort by slice number\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# Process all images in the directory\n",
    "def process_all_images(directory):\n",
    "    sorted_filenames = retrieve_n_sort(directory)\n",
    "    image_tensors = [prepare_image_for_tf(os.path.join(directory, filename)) for filename in sorted_filenames]\n",
    "    return tf.stack(image_tensors)  # Stack into a batch tensor\n",
    "\n",
    "# Process images in the directory\n",
    "image_batch = process_all_images(mydir)\n",
    "print(f\"Processed Image Batch Shape: {image_batch.shape}\") # Processed Image Batch Shape: (48, 160, 160, 1)  48 refers to the batch size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's reexamine the shape and intensity of the images\n",
    "# for brain_img in image_batch:\n",
    "    \n",
    "#     print(\"Brain Image range: Min =\", tf.reduce_min(brain_img).numpy(), \n",
    "#           \"Max =\", tf.reduce_max(brain_img).numpy())\n",
    "    \n",
    "# yes, its min = 0 and max = 255 now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show brain figures that we want to visualize\n",
    "# View 10 random brain image and mask from training data:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "for image in image_batch:  # Let's examine five pairs\n",
    "    # i: represent index var for each iteration\n",
    "    # Show brain image\n",
    "    squeezed_brain_img = tf.squeeze(image, axis=-1)  # Remove the channel dimension (which indicates greyscale)\n",
    "    plt.imshow(squeezed_brain_img, cmap=\"gray\")\n",
    "    plt.title(f\"Brain Image {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout() \n",
    "    # plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "Your loss function class initiate successfully!\n",
      "Model Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import load_model\n",
    "from loss_funcs import loss_function\n",
    "\n",
    "# create the instance\n",
    "my_loss_func = loss_function()\n",
    "\n",
    "dice_coefficient = my_loss_func.dice_coefficient\n",
    "dice_loss = my_loss_func.dice_loss\n",
    "\n",
    "\n",
    "# Load the train model:\n",
    "saved_model_path = \"/home/smooi/vibes_auto_pipe/unet_w_aug.h5\"\n",
    "model = load_model(saved_model_path, custom_objects={\"dice_loss\": dice_loss, \"dice_coefficient\": dice_coefficient})\n",
    "print(\"Model Loaded Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 13:39:41.279369: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-02-14 13:39:41.281861: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3609600000 Hz\n"
     ]
    }
   ],
   "source": [
    "# Make the predictions \n",
    "predictions = model.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "predicted_mask = binary_predictions.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# with PdfPages('trial1.pdf') as pdf:\n",
    "#     for image in image_batch:  # Iterate over individual images\n",
    "#         # Expand dimensions to add batch size of 1 (for single-image prediction)\n",
    "#         image_expanded = np.expand_dims(image, axis=0)  # Shape: (1, 160, 160, 1)\n",
    "\n",
    "#         # Predict the mask\n",
    "#         predicted_mask = model.predict(image_expanded)  # Output shape: (1, 160, 160, 1)\n",
    "#         predicted_mask = (predicted_mask > 0.5).astype(int).squeeze()  # Remove batch dimension\n",
    "\n",
    "#         # Plot input image and predicted mask\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "\n",
    "#         # Input image\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.title(\"Input Image\")\n",
    "#         plt.imshow(image[:, :, 0], cmap='gray')  # Original shape: (160, 160, 1)\n",
    "#         plt.axis('off')\n",
    "\n",
    "#         # Predicted mask\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.title(\"Predicted Mask\")\n",
    "#         plt.imshow(predicted_mask, cmap='gray')  # Predicted mask shape: (160, 160)\n",
    "#         plt.axis('off')\n",
    "\n",
    "#         # Save the figure to the PDF\n",
    "#         print(\"Saving figure...\")\n",
    "#         pdf.savefig()\n",
    "#         plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 160, 160)\n",
      "(160, 160, 56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smooi/miniconda3/envs/tf_env/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Image data has type int64, which may cause incompatibilities with other tools. This will error in NiBabel 5.0. This warning can be silenced by passing the dtype argument to Nifti1Image().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "print(predicted_mask.shape)\n",
    "predicted_mask_reordered = np.transpose(predicted_mask, (1, 2, 0))\n",
    "print(predicted_mask_reordered.shape)\n",
    "\n",
    "# In order to transfer this back to the nii file,\n",
    "# we have to follow the original nifti file format,\n",
    "# which should have the slice number at the end (e.g. (160, 160, 48))\n",
    "\n",
    "# Create an nifti object\n",
    "affine = nifti.affine\n",
    "new_nifti = nib.Nifti1Image(predicted_mask_reordered, affine)\n",
    "saved_dir = \"/home/smooi/vibes_auto_pipe/result/Cc106_t2bet_mask.nii\"\n",
    "\n",
    "# change the format \n",
    "nib.save(new_nifti, saved_dir)\n",
    "# print(\"NIfTI file saved as 'predicted_masks1.nii'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NIfTI shape: (160, 160, 56)\n"
     ]
    }
   ],
   "source": [
    "# verify the aboved saved file\n",
    "saved_nifti = nib.load(saved_dir)\n",
    "loaded_data = saved_nifti.get_fdata()\n",
    "\n",
    "print(f\"Loaded NIfTI shape: {loaded_data.shape}\")  # Should match your mask shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
